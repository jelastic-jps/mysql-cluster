jpsType: update
id: percona-xtradb-cluster
name: Percona XtraDB Cluster
description: Percona XtraDB Auto Clustering

baseUrl: https://raw.githubusercontent.com/sych74/mysql-cluster/JE-64510

success:
  text: /texts/phpmyadmin-credentials.md

nodeGroupAlias:
  "${targetNodes.nodeGroup}": sqldb

mixins:
  - /scripts/common.yml

globals:
  DB_USER: ${settings.db_user:user-[fn.random]}
  DB_PASS: ${settings.db_pass:[fn.password(20)]}
  CLUSTER_NAME: xtradb-${env.name}
  CLUSTER_CONF: /etc/mysql/conf.d/xtradb.cnf

onAfterScaleOut[sqldb]:
  - forEach(event.response.nodes):
      initialSetup:
        id: ${@i.id}
  - setupSeeds
  - forEach(event.response.nodes):
    - setupInstance:
        id: ${@i.id}
        ip: ${@i.intIP}
    - wsrepSlaveThreads:
        id: ${@i.id}
    - cmd[${@i.id}]: jem service restart

onAfterScaleIn[sqldb]: setupSeeds
  
onAfterMigrate:
  - script: delete MANIFEST.id; return {result:0, jps:MANIFEST};
  - install: ${response.jps}
    nodeGroup: sqldb

onAfterClone:
  - script: delete MANIFEST.id; return {result:0, jps:MANIFEST};
  - install: ${response.jps}
    envName: ${event.response.env.envName}
    nodeGroup: sqldb

onBeforeStop:
  - forEach(i:nodes.sqldb):
      env.control.StopNode [${@i.id}]
      
onAfterStart:   
  - if (nodes.proxy):
      cmd[proxy]: sudo service proxysql restart

onBeforeRestartNode[sqldb]:
  - forEach(i:nodes.sqldb):
      cmd [${@i.id}]: sudo jem service restart
  - stopEvent:
      type: success
      message: Galera cluster successfully restarted

onAfterSetCloudletCount[sqldb]:
  - forEach(i:nodes.sqldb):
    - wsrepSlaveThreads:
        id: ${@i.id}
    - cmd [${@i.id}]: sudo jem service restart;

onInstall:
  - getReplicaUser
  - resetCluster
  - restartNodesInOrder
  - initialSetup:
      id: sqldb
  - setupSeeds
  - forEach(i:nodes.sqldb):
      - setupInstance:
          id: ${@i.id}
          ip: ${@i.intIP}
      - wsrepSlaveThreads:
          id: ${@i.id}
  - firstStartCluster
  - env.file.AddFavorite:
    nodeGroup: sqldb
    path: /var/lib/mysql/grastate.dat
    keyword: grastate.dat
    isDir: false

actions:
  initialSetup:
    - setupUsers:
        id: ${this.id}
    - setNodeDisplayName[${this.id}]: XtraDB
    - cmd[${this.id}]: |-
        [ -e /etc/systemd/system/mysql.service.d ] && wget ${baseUrl}/scripts/percona-systemd-override.conf -O /etc/systemd/system/mysql.service.d/bootstrap.conf || wget ${baseUrl}/scripts/mysql -O /etc/init.d/mysql;
        chmod +x /usr/local/sbin/setMySQLOOMScore; echo '/etc/systemd/system/mysql.service.d/bootstrap.conf' >> /etc/jelastic/redeploy.conf; systemctl daemon-reload;
      user: root
    - cmd[${this.id}]: |-
        wget ${baseUrl}/configs/xtradb.cnf -O ${globals.CLUSTER_CONF} &>> /var/log/run.log;
 
  setupSeeds:
    script: |
      var resp = jelastic.env.control.GetEnvInfo('${env.envName}', session);
      if (resp.result != 0) return resp;
      var intIP = [];
      for (var i = 0, n = resp.nodes; i < n.length; i++)
        n[i].nodeGroup == "sqldb" ? intIP.push(n[i].intIP) : 0
      resp = {result:0, onAfterReturn: {}};
      resp.onAfterReturn['cmd[sqldb]'] = 'sed -i "s|wsrep_cluster_address.*|wsrep_cluster_address = gcomm://'+ intIP.join(',') +'|g " ${globals.CLUSTER_CONF}';
      resp.onAfterReturn['user'] = 'root';
      return resp;
  
  setupInstance:
    cmd[${this.id}]: |-
      sed -i "s/bind-address.*/bind-address = $(hostname | cut -d'-' -f 1)/" ${globals.CLUSTER_CONF}
      sed -i "s/report_host.*/report_host = $(hostname | cut -d'-' -f 1)/" ${globals.CLUSTER_CONF}
      sed -i "s/wsrep_cluster_name.*/wsrep_cluster_name = ${globals.CLUSTER_NAME}/" ${globals.CLUSTER_CONF}
      sed -i "s/wsrep_node_name.*/wsrep_node_name = $(hostname | cut -d'-' -f 1)/" ${globals.CLUSTER_CONF}
      sed -i "s/wsrep_node_address.*/wsrep_node_address = ${this.ip}/" ${globals.CLUSTER_CONF}

  wsrepSlaveThreads:
    cmd[${this.id}]: sed -i "s/wsrep_slave_threads.*/wsrep_slave_threads = $(nproc --all)/" ${globals.CLUSTER_CONF}

  resetCluster:
    - cmd[sqldb]: |-
        [ -f ${globals.CLUSTER_CONF} ] && rm -f ${globals.CLUSTER_CONF}
        [ -f /var/lib/mysql/grastate.dat ] && rm -f /var/lib/mysql/grastate.dat
        [ -f /var/lib/mysql/gvwstate.dat ] && rm -f /var/lib/mysql/gvwstate.dat
        [ -f /var/lib/mysql/galera.cache ] && rm -f /var/lib/mysql/galera.cache
        pgrep mysql 1>/dev/null && pkill -9 mysql;
        pgrep mariadb 1>/dev/null && pkill -9 mariadb || true
      user: root
 
  restartNodesInOrder:
    - forEach(i:nodes.sqldb):
        cmd [${@i.id}]: sudo jem service restart

  firstStartCluster:
    - cmd[${nodes.sqldb.master.id}]: jem service stop; sleep 5; pkill -9 mysql; pkill -9 mariadb;
      user: root
    - cmd[${nodes.sqldb.master.id}]: |-
        echo "safe_to_bootstrap: 1" > /var/lib/mysql/grastate.dat;
        sudo jem service restart;
    - forEach(n:nodes.sqldb):
        if (!${@n.ismaster}):
          cmd[${@n.id}]: sudo jem service restart

  redeployGalera:
    - forEach(nodes.sqldb):
        - log: "Redeploying MariaDB on node ${@i.id}..."
        - cmd[${@i.id}]: sudo jem service stop
        - api: environment.control.RedeployContainerById
          nodeId: ${@i.id}
          tag: ${this.targetDockerTag}
          useExistingVolumes: true
          skipReinstall: false
          envName: ${env.envName}
