jpsType: update
id: mysql-proxy-master-slave-cluster
name: MySQL/MariaDB/Percona Database Cluster with ProxySQL
description: ProxySQL Load Balancer Entry Point

baseUrl: https://raw.githubusercontent.com/sych74/mysql-cluster/v3.0.0

success: /texts/proxy-entrypoint.md

nodeGroupAlias:
  "${targetNodes.nodeGroup}": sqldb

mixins:
  - /scripts/common.yml

globals:
  DB_USER: "${settings.db_user}"
  DB_PASS: "${settings.db_pass}"
  SCHEME: "${settings.scheme}"
  ORCH_PASS: "${fn.password(10)}"
  ADMIN_USER: "admin-${fn.random}"
  ADMIN_PASS: "${fn.password(10)}"
  MAX_REPL_LAG: 20
  
onBeforeRemoveNode[proxy]:
  stopEvent:
    type: warning
    message: Scaling is not supported for ProxySQL.

onBeforeAddNode[proxy]:
  stopEvent:
    type: warning
    message: Scaling is not supported for ProxySQL.

onAfterScaleOut[sqldb]:
  forEach(event.response.nodes):
  - addSlave:
      id: "${@i.id}"

onBeforeScaleIn[sqldb]:
  forEach(event.response.nodes):
    removeSlave:
      id: "${@i.id}"
      
onAfterScaleIn[sqldb]:
  forEach(event.response.nodes):
    cmd[proxy]: MYSQL_PWD=${globals.ORCH_PASS} mysql -h 127.0.0.1 -P3360 -uadmin -e "DELETE FROM orchestrator.database_instance where hostname='node${@i.id}-${env.domain}';"

onAfterClone:
  install: ${baseUrl}/scripts/proxy-master-slave.jps?_r=${fn.random}
  envName: ${event.response.env.envName}
  nodeGroup: sqldb
  settings:
    db_user: "${globals.DB_USER}"
    db_pass: "${globals.DB_PASS}"

onAfterMigrate:
  install: ${baseUrl}/scripts/proxy-master-slave.jps?_r=${fn.random}
  nodeGroup: sqldb
  settings:
    db_user: "${globals.DB_USER}"
    db_pass: "${globals.DB_PASS}"

onInstall:
  - getReplicaUser
  - resetProxyNodes
  - setupOrchestrator
  - setupProxySQL

  - if ('${globals.SCHEME}'.toLowerCase() == 'master'):
    - setGlobals:
        MAX_REPL_LAG: 0
    - getMastersIDs
    - addMaster:
        id: "${globals.master1_id}"
    - addMaster:
        id: "${globals.master2_id}"
    - forEach(k:nodes.sqldb):
        addSlave:
          id: "${@k.id}"

  - if ('${globals.SCHEME}'.toLowerCase() != 'master'):
      forEach(l:nodes.sqldb):
        - if (${@l.ismaster}):
            addMaster:
              id: "${@l.id}"
        - addSlave:
            id: "${@l.id}"

actions:

  setupOrchestrator:
    - log: Orchestrator configuration
    - cmd [proxy]: |-
        mysql -h 127.0.0.1 -P3360 -uroot -e "DROP DATABASE IF EXISTS orchestrator;"
        mysql -h 127.0.0.1 -P3360 -uroot -e "CREATE DATABASE IF NOT EXISTS orchestrator;"
        mysql -h 127.0.0.1 -P3360 -uroot -e "GRANT ALL PRIVILEGES ON orchestrator.* TO 'admin'@'127.0.0.1' IDENTIFIED BY '${globals.ORCH_PASS}';"
        wget ${baseUrl}/configs/orchestrator.conf.json -O /etc/orchestrator.conf.json &>> /var/log/run.log
        sed -i -e 's|orc_client_user|${globals.DB_USER}|g' /etc/orchestrator.conf.json
        sed -i -e 's|orc_client_password|${globals.DB_PASS}|g' /etc/orchestrator.conf.json
        sed -i -e 's|orc_server_user|admin|g' /etc/orchestrator.conf.json
        sed -i -e 's|orc_server_password|${globals.ORCH_PASS}|g' /etc/orchestrator.conf.json
        sed -i -e 's|HTTP_Auth_User|admin|g' /etc/orchestrator.conf.json
        sed -i -e 's|HTTP_Auth_Password|${globals.ORCH_PASS}|g' /etc/orchestrator.conf.json
        systemctl restart orchestrator
      user: root

  setupProxySQLCluster:
    - log: ProxySQL clusterization
    - cmd [proxy]: |-
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value='admin:admin;${globals.ADMIN_USER}:${globals.ADMIN_PASS}' WHERE variable_name='admin-admin_credentials';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value='0.0.0.0:6032' WHERE variable_name='admin-mysql_ifaces';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value='${globals.ADMIN_USER}' WHERE variable_name='admin-cluster_username';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value='${globals.ADMIN_PASS}' WHERE variable_name='admin-cluster_password';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value=200 WHERE variable_name='admin-cluster_check_interval_ms';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value=100 WHERE variable_name='admin-cluster_check_status_frequency';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value='true' WHERE variable_name='admin-cluster_mysql_servers_save_to_disk';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value=1 WHERE variable_name='admin-cluster_mysql_servers_diffs_before_sync';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "load admin variables to RUNTIME; save admin variables to disk;"
    - forEach(n:nodes.proxy):
      - cmd [proxy]: |-
          MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "INSERT INTO proxysql_servers (hostname,port,weight,comment) VALUES ('${@n.address}',6032,100,'CLUSTER');"
          MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD PROXYSQL SERVERS TO RUNTIME; SAVE PROXYSQL SERVERS TO DISK;"

  setupProxySQL:
    - log: ProxySQL configuration
    - cmd [proxy]: |-
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "INSERT INTO mysql_replication_hostgroups VALUES (10,11,'read_only','Group setup');"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "INSERT INTO mysql_users (username, password, active, default_hostgroup, max_connections) 
          VALUES ('${globals.DB_USER}', '${globals.DB_PASS}', 1, 10, 1000);"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "INSERT INTO mysql_query_rules (active, match_pattern, destination_hostgroup, apply) VALUES (1, '^SELECT.*', 11, 1);"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "INSERT INTO mysql_query_rules (active, match_pattern, destination_hostgroup, apply) VALUES (1, '^SELECT.*FOR UPDATE', 10, 1);"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value='${globals.REPLICA_USER}' WHERE variable_name='mysql-monitor_username';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value='${globals.REPLICA_PSWD}' WHERE variable_name='mysql-monitor_password';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value='${nodes.sqldb.version}' WHERE variable_name='mysql-server_version';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD MYSQL VARIABLES TO RUNTIME; SAVE MYSQL VARIABLES TO DISK;"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD MYSQL SERVERS TO RUNTIME; SAVE MYSQL SERVERS TO DISK;"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD MYSQL USERS TO RUNTIME; SAVE MYSQL USERS TO DISK;"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD MYSQL QUERY RULES TO RUNTIME; SAVE MYSQL QUERY RULES TO DISK;"

  addMaster:
    cmd [proxy]: |-
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "INSERT INTO mysql_servers (hostgroup_id, hostname, port) VALUES (10, 'node${this.id}', 3306);"
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin  -e "LOAD MYSQL SERVERS TO RUNTIME; SAVE MYSQL SERVERS TO DISK;"
      MYSQL_PWD=${globals.DB_PASS} mysql -u${globals.DB_USER} -hnode${this.id} -e "show slave hosts;"
      /usr/local/orchestrator/orchestrator -c discover -i node${this.id} cli;
    user: root
  
  addSlave:
    cmd[proxy]: |-
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin  -e "INSERT INTO mysql_servers (hostgroup_id, hostname, port, max_replication_lag) 
        VALUES (11, 'node${this.id}', 3306, '${globals.MAX_REPL_LAG}');"
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin  -e "LOAD MYSQL SERVERS TO RUNTIME;SAVE MYSQL SERVERS TO DISK;"

  removeSlave:
    cmd[proxy]: |-
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin  -e "DELETE FROM mysql_servers WHERE hostname = 'node${this.id}';"
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin  -e "LOAD MYSQL SERVERS TO RUNTIME; SAVE MYSQL SERVERS TO DISK;"
      MYSQL_PWD=${globals.ORCH_PASS} mysql -h 127.0.0.1 -P3360 -uadmin  -e "DELETE FROM orchestrator.database_instance where hostname='node${this.id}-${env.domain}';"
      
  resetProxyNodes:
    cmd[proxy]: |-
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "delete from mysql_replication_hostgroups; delete from mysql_users; delete from scheduler; delete from mysql_servers;"
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "SAVE MYSQL VARIABLES TO DISK;"
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "SAVE MYSQL SERVERS TO DISK;"
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "SAVE MYSQL USERS TO DISK;"
      mysql -h 127.0.0.1 -P3360 -uroot -e "DROP DATABASE IF EXISTS orchestrator;"
      sudo service proxysql restart;

  getMastersIDs:
    - script: |
        var envInfo, resp, groups,
            onAfterReturn = { setGlobals: {} },
            glbs = onAfterReturn.setGlobals;
        resp = jelastic.env.control.ExecCmdByGroup('${env.envName}', session, "sqldb", toJSON([{ "command": '[ -f "/etc/mysql/conf.d/master.cnf" ] && echo "YES" || echo "NO";' }]), false, false, "root");
        if (resp.result != 0) return resp;
        groups = resp.responses;
        for (var i = 0, n = groups.length; i < n; i++) {
          if (groups[i].out == "YES") {
            envInfo = jelastic.env.control.GetEnvInfo('${env.envName}', session);
            for (var node = 0, nodes = envInfo.nodes; node < nodes.length; node++) {
              if (nodes[node].id == groups[i].nodeid)
                nodes[node].ismaster ? glbs["master1_id"] = groups[i].nodeid : glbs["master2_id"] = groups[i].nodeid;
            }
          }
        }
        return { result: 0, onAfterReturn: onAfterReturn };
