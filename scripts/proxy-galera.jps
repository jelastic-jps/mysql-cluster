jpsType: update
id: mysql-proxy-galera-cluster
name: MariaDB Galera Cluster with ProxySQL
description: MariaDB Galera Cluster

baseUrl: https://raw.githubusercontent.com/jelastic-jps/mysql-cluster/v2.4.1

success: /texts/proxy-entrypoint.md

nodeGroupAlias:
  "${targetNodes.nodeGroup}": sqldb

globals:
  PATH: "${settings.path}"
  DB_USER: "${settings.db_user}"
  DB_PASS: "${settings.db_pass}"
  ORCH_PASS: "${fn.password(10)}"
  
onAfterScaleOut[sqldb]:
  - forEach(event.response.nodes):
      addNode:
        id: "${@i.id}"

onBeforeScaleIn[sqldb]:
  - forEach(event.response.nodes):
      removeNode:
        id: "${@i.id}"
  - cmd[proxy]: 'MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD MYSQL SERVERS TO RUNTIME; SAVE MYSQL SERVERS TO DISK;" '
  
onAfterMigrate:
  install: ${globals.PATH}/scripts/proxy-galera.jps?_r=${fn.random}
  nodeGroup: sqldb
  settings:
    db_user: "${globals.DB_USER}"
    db_pass: "${globals.DB_PASS}"
    path: "${globals.PATH}"
    
onAfterClone:
  install: ${globals.PATH}/scripts/proxy-galera.jps?_r=${fn.random}
  envName: ${event.response.env.envName}
  nodeGroup: sqldb
  settings:
    db_user: "${globals.DB_USER}"
    db_pass: "${globals.DB_PASS}"
    path: "${globals.PATH}"

onBeforeRemoveNode[proxy]:
  stopEvent:
    type: warning
    message: Scaling is not supported for ProxySQL.

onBeforeAddNode[proxy]:
  stopEvent:
    type: warning
    message: Scaling is not supported for ProxySQL.

onInstall:

  - getMonitorUser

  - resetProxyNodes

  - cmd[proxy]: |-
      mysql -h 127.0.0.1 -P3360 -uroot -e "CREATE DATABASE IF NOT EXISTS orchestrator;"
      mysql -h 127.0.0.1 -P3360 -uroot -e "GRANT ALL PRIVILEGES ON orchestrator.* TO 'admin'@'127.0.0.1' IDENTIFIED BY '${globals.ORCH_PASS}';"
      wget ${globals.PATH}/configs/orchestrator.conf.json -O /etc/orchestrator.conf.json &>> /var/log/run.log
      sed -i -e 's|orc_client_user|${globals.DB_USER}|g' /etc/orchestrator.conf.json
      sed -i -e 's|orc_client_password|${globals.DB_PASS}|g' /etc/orchestrator.conf.json
      sed -i -e 's|orc_server_user|admin|g' /etc/orchestrator.conf.json
      sed -i -e 's|orc_server_password|${globals.ORCH_PASS}|g' /etc/orchestrator.conf.json
      sed -i -e 's|HTTP_Auth_User|admin|g' /etc/orchestrator.conf.json
      sed -i -e 's|HTTP_Auth_Password|${globals.ORCH_PASS}|g' /etc/orchestrator.conf.json
      systemctl restart orchestrator; sleep 5
    user: root

  - if(${fn.compare([nodes.proxy.master.version], 2.0)} > 0): initGaleraForProxy2

  - if(${fn.compare([nodes.proxy.master.version], 2.0)} < 0): initGaleraForProxy1
 
  - forEach(nodes.sqldb):
    - addNode:
        id: "${@i.id}"
         
actions:
  getMonitorUser:
    - env.control.GetContainerEnvVarsByGroup[sqldb]
    - setGlobals:
        MONITOR_USER: ${response.object.MONITOR_USER}
        MONITOR_PSWD: ${response.object.MONITOR_PSWD}
    - if (/response/.test("${globals.MONITOR_USER}") || /response/.test("${globals.MONITOR_PSWD}")):
        return:
          type: error
          message: Monitor user does not exist

  initGaleraForProxy1:
    - cmd[proxy]: |-
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "INSERT INTO mysql_replication_hostgroups VALUES (2,3,'Group setup');"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "INSERT INTO mysql_users (username,password,default_hostgroup) VALUES ('${globals.DB_USER}', '${globals.DB_PASS}', 2);"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value='${globals.MONITOR_USER}' WHERE variable_name='mysql-monitor_username';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value='${globals.MONITOR_PSWD}' WHERE variable_name='mysql-monitor_password';"
        wget ${globals.PATH}/scripts/proxysql_galera_checker.sh -O /var/lib/proxysql/proxysql_galera_checker.sh &>> /var/log/run.log; chmod +x /var/lib/proxysql/proxysql_galera_checker.sh
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "INSERT INTO scheduler(id,interval_ms,filename,arg1,arg2,arg3,arg4) VALUES
        (1,'2000','/var/lib/proxysql/proxysql_galera_checker.sh','127.0.0.1','6032','2', '/var/lib/proxysql/proxysql_galera_checker.log');"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD SCHEDULER TO RUNTIME; SAVE SCHEDULER TO DISK;"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD MYSQL VARIABLES TO RUNTIME; SAVE MYSQL VARIABLES TO DISK;"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD MYSQL USERS TO RUNTIME; SAVE MYSQL USERS TO DISK;"
  
  initGaleraForProxy2:
    - cmd[proxy]: |-
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "INSERT INTO mysql_galera_hostgroups (writer_hostgroup,backup_writer_hostgroup,reader_hostgroup,offline_hostgroup,active,max_writers,writer_is_also_reader,max_transactions_behind) 
        VALUES (2,4,3,1,1,3,1,100);"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "INSERT INTO mysql_users (username,password,default_hostgroup) VALUES ('${globals.DB_USER}', '${globals.DB_PASS}', 2);"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value='${globals.MONITOR_USER}' WHERE variable_name='mysql-monitor_username';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "UPDATE global_variables SET variable_value='${globals.MONITOR_PSWD}' WHERE variable_name='mysql-monitor_password';"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD SCHEDULER TO RUNTIME; SAVE SCHEDULER TO DISK;"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD MYSQL VARIABLES TO RUNTIME; SAVE MYSQL VARIABLES TO DISK;"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD MYSQL USERS TO RUNTIME; SAVE MYSQL USERS TO DISK;"
        
  addNode:
    cmd[proxy]: |-
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "INSERT INTO mysql_servers (hostgroup_id,hostname, port) VALUES (2, 'node${this.id}', 3306);"
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD MYSQL SERVERS TO RUNTIME; SAVE MYSQL SERVERS TO DISK;"
      MYSQL_PWD=${globals.DB_PASS} mysql -u${globals.DB_USER} -hnode${this.id} -e "show slave hosts;"
      /usr/local/orchestrator/orchestrator -c discover -i node${this.id} cli
    user: root

  removeNode:
    cmd[proxy]: |-
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "DELETE FROM mysql_servers WHERE hostname = 'node${this.id}';"
      MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "LOAD MYSQL SERVERS TO RUNTIME; SAVE MYSQL SERVERS TO DISK;"
      MYSQL_PWD=${globals.ORCH_PASS} mysql -h 127.0.0.1 -P3360 -uadmin -e "DELETE FROM orchestrator.database_instance where hostname='node${this.id}';"
   
  resetProxyNodes:
    - if(${fn.compare([nodes.proxy.master.version], 2.0)} > 0):
        cmd[proxy]: MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "delete from mysql_galera_hostgroups; delete from mysql_users; delete from mysql_servers;"
    - if(${fn.compare([nodes.proxy.master.version], 2.0)} < 0):
        cmd[proxy]: MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "delete from mysql_replication_hostgroups; delete from mysql_users; delete from scheduler; delete from mysql_servers;"
    - cmd[proxy]: |-  
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "SAVE MYSQL VARIABLES TO DISK;"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "SAVE MYSQL SERVERS TO DISK;"
        MYSQL_PWD=admin mysql -h 127.0.0.1 -P6032 -uadmin -e "SAVE MYSQL USERS TO DISK;"
        mysql -h 127.0.0.1 -P3360 -uroot -e "DROP DATABASE IF EXISTS orchestrator;"
        sudo service proxysql restart;
